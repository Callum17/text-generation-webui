version: "3.3"
services:
  text-generation-webui:
    restart: unless-stopped
    build:
      context: .
      args:
        # If not specified Dockerfile will try to build for all common architectures
        TORCH_CUDA_ARCH_LIST: "${TORCH_CUDA_ARCH_LIST:-3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6+PTX}"
    shm_size: '1gb'
    env_file: .env
    ports:
      - "${HOST_PORT:-7860}:${CONTAINER_PORT:-7860}"
      - "${HOST_API_PORT:-5000}:${CONTAINER_API_PORT:-5000}"
      - "${HOST_API_STREAM_PORT:-5005}:${CONTAINER_API_STREAM_PORT:-5005}"
    stdin_open: true
    tty: true
    volumes:
      - ./characters:/home/app/text-generation-webui/characters
      - ./extensions:/home/app/text-generation-webui/extensions
      - ./loras:/home/app/text-generation-webui/loras
      - ./models:/home/app/text-generation-webui/models
      - ./presets:/home/app/text-generation-webui/presets
      - ./prompts:/home/app/text-generation-webui/prompts
      - ./training:/home/app/text-generation-webui/training
      - ./softprompts:/home/app/text-generation-webui/softprompts
      - ./cloudflared:/etc/cloudflared
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]